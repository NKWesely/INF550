---
title: "INF 550 Section 7.4.5"
author: "Natasha Wesely"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#
```{r, include=FALSE}
# Packages you will need for AppEEARS API Tutorials
packages = c('getPass','httr','jsonlite','ggplot2','dplyr','tidyr','readr','geojsonio','geojsonR','rgdal','sp', 'raster', 'rasterVis', 'RColorBrewer', 'jsonlite')



# Identify missing packages
new.packages = packages[!(packages %in% installed.packages()[,"Package"])]

# Loop through and download the required packages
if (length(new.packages)[1]==0){
  message('All packages already installed')
}else{
  for (i in 1:length(new.packages)){
    message(paste0('Installing: ', new.packages))
    install.packages(new.packages[i])
  }
}

```

```{r}
# Load necessary packages into R                                               
library(getPass)            # A micro-package for reading passwords
library(httr)               # To send a request to the server/receive a response from the server
library(jsonlite)           # Implements a bidirectional mapping between JSON data and the most important R data types
library(ggplot2)            # Functions for graphing and mapping
library(tidyr)              # Function for working with tabular data
library(dplyr)              # Function for working with tabular data
library(readr)              # Read rectangular data like CSV
```

## Question 1 
**Choose two NEON sites in different ecoregions. Then complete the following for each of your two NEON sites:**

I am choosing the NEON sites JORN & TEAK.

## Question 2
**Using your Earth Data account submit a point-based request to AppEEARS to pull 250m NDVI from AQUA and TERA for 2017, 2018, & 2019.**


```{r}
# Set Up the Output Directory
# Set your input directory, and create an output directory for the results.
outDir <- file.path('./data/')                 # Create an output directory if it doesn't exist
suppressWarnings(dir.create(outDir)) 
```


```{r}
# Login to Earth Data
# To submit a request, you must first login to the AppEEARS API. Use your private R Script to enter your NASA Earthdata login Username and Password.
load('EARTHDATA_Token.Rdata')
exists('EARTHDATA_User')

# rename my user name id for simplicity
user = EARTHDATA_User
password = EARTHDATA_Password

# Decode the username and password to be used to post login request.
secret <- jsonlite::base64_enc(paste(user, password, sep = ":"))  # Encode the string of username and password
# Next, assign the AppEEARS API URL to a static variable.
API_URL = "https://appeears.earthdatacloud.nasa.gov/api/"  # Set the AppEEARS API to a variable
```


```{r}
# Use the httr package to post your username and password. A successful login will provide you with a token to be used later in this tutorial to submit a request. For more information or if you are experiencing difficulties, please see the API Documentation.

# Insert API URL, call login service, set the component of HTTP header, and post the request to the server
response <- httr::POST(paste0(API_URL,"login"), 
                       add_headers("Authorization" = paste("Basic", gsub("\n", "", secret)),
                                   "Content-Type" ="application/x-www-form-urlencoded;charset=UTF-8"),
                       body = "grant_type=client_credentials")

response_content <- content(response)                          # Retrieve the content of the request
token_response <- toJSON(response_content, auto_unbox = TRUE)  # Convert the response to the JSON object
remove(user, password, secret, response)                       # Remove the variables that are not needed anymore 
prettify(token_response)  
```

```{r}
# Query Available Products
# The product API provides details about all of the products and layers available in AppEEARS. For more information, please see the API Documentation.
# 
# Below, call the product API to list all of the products available in AppEEARS.

prods_req <- GET(paste0(API_URL, "product"))             # Request the info of all products from product service
prods_content <- content(prods_req)                      # Retrieve the content of request 
all_Prods <- toJSON(prods_content, auto_unbox = TRUE)    # Convert the info to JSON object
remove(prods_req, prods_content)                         # Remove the variables that are not needed anymore
# prettify(all_Prods)
```


```{r}
# Search and Explore Available Products
# Create a list indexed by product name to make it easier to query a specific product.

# Divides information from each product.
divided_products <- split(fromJSON(all_Prods), seq(nrow(fromJSON(all_Prods))))
# Create a list indexed by the product name and version
products <- setNames(divided_products,fromJSON(all_Prods)$ProductAndVersion)
# Print no. products available in AppEEARS
sprintf("AppEEARS currently supports %i products." ,length(products))   
```

```{r, eval=F, include=F}
# Next, look at the product’s names and descriptions. Below, the ‘ProductAndVersion’ and ‘Description’ are printed for aßll products.

# Loop through the products in the list and print the product name and description
for (p in products){                                   
  print(paste0(p$ProductAndVersion," is ",p$Description," from ",p$Source))  
}
```


```{r, include = F, eval = FALSE}
# the product service provides many useful details, including if a product is currently available in AppEEARS, a description, and information on the spatial and temporal resolution. Below, the product details are retrieved using ‘ProductAndVersion’.

# Convert the MCD15A3H.006 info to JSON object and print the prettified info
prettify(toJSON(products$"MCD15A3H.006")) 
```


```{r, include = F, eval = FALSE}
# also, the products can be searched using their description. Below, search for products containing Leaf Area Index in their description and make a list of their productAndVersion.

# LAI_Products <- list()                                        # Create an empty list 
# for (p in products){                                          # Loop through the product list
#   if (grepl('Leaf Area Index', p$Description )){              # Look through the product description for a keyword 
#     LAI_Products <- append(LAI_Products, p$ProductAndVersion) # Append the LAI products to the list
#   }
# }
# LAI_Products

# make a list of all NDVI products
NDVI_Products <- list()                                        # Create an empty list
for (p in products){                                          # Loop through the product list
  if (grepl('NDVI', p$Description )){              # Look through the product description for a keyword
    NDVI_Products <- append(NDVI_Products, p$ProductAndVersion) # Append the LAI products to the list
  }
}

# make a list of all 250 m prodcuts
m250_Products <- list() 
for (p in products){
  if (grepl('250m', p$Resolution )){ 
    m250_Products = append(m250_Products, p$ProductAndVersion)
  }
}

# make a list of both NDVI products and 250m products
intersect(NDVI_Products, m250_Products)
```


```{r}
# Using the info above, Create a list of desired products.

desired_products <- c('MOD13Q1.006','MYD13Q1.006')   # Create a vector of desired products 
desired_products
```

```{r}
# Search and Explore Available Layers
# This API call will list all of the layers available for a given product. Each product is referenced by its ProductAndVersion property which is also referred to as the product_id. 
# First, request the layers for the MOD13Q1.006 product.

# Request layers for the 1st product in the list: MOD13Q1.006
MOD13Q1_req <- GET(paste0(API_URL,"product/", desired_products[1]))  # Request the info of a product from product URL
MOD13Q1_content <- content(MOD13Q1_req)                             # Retrieve content of the request 
MOD13Q1_response <- toJSON(MOD13Q1_content, auto_unbox = TRUE)      # Convert the content to JSON object
remove(MOD13Q1_req, MOD13Q1_content)                                # Remove the variables that are not needed anymore
#prettify(MOD13Q1_response)                                          # Print the prettified response
names(fromJSON(MOD13Q1_response))


# Request layers for the 1st product in the list: MYD13Q1.006
MYD13Q1.006_req <- GET(paste0(API_URL,"product/", desired_products[2]))  # Request the info of a product from product URL
MYD13Q1.006_content <- content(MYD13Q1.006_req)                             # Retrieve content of the request 
MYD13Q1.006_response <- toJSON(MYD13Q1.006_content, auto_unbox = TRUE)      # Convert the content to JSON object
remove(MYD13Q1.006_req, MYD13Q1.006_content)                                # Remove the variables that are not needed anymore
#prettify(MOD13Q1_response)                                          # Print the prettified response
names(fromJSON(MYD13Q1.006_response))
```


```{r}
# lastly, select the desired layers and pertinent products and make a data frame using this information. This data frame will be inserted into the nested data frame that will be used to create a JSON object to submit a request in Section 3.

# Create a vector of desired layers
desired_layers <- c("_250m_16_days_NDVI") 

# Create a data frame including the desired data products and layers
layers <- data.frame(product = desired_products, layer = desired_layers)
```


```{r}
# the Submit task API call provides a way to submit a new request to be processed. It can accept data via JSON or query string. In the example below, create a JSON object and submit a request. Tasks in AppEEARS correspond to each request associated with your user account. Therefore, each of the calls to this service requires an authentication token.

# in this section, begin by setting up the information needed for a nested data frame that will be later converted to a JSON object for submitting an AppEEARS point request. For detailed information on required JSON parameters, see the API Documentation.

# For point requests, beside the date range and desired layers information, the coordinates property must also be inside the task object. Optionally, set id and category properties to further identify your selected coordinates.

# We’ll start by requesting point-based data for NEON.D17.SOAP and NEON.D17.SJER:

startDate <- "01-01-2017"       # Start of the date range for  which to extract data: MM-DD-YYYY
endDate <- "12-31-2019"         # End of the date range for  which to extract data: MM-DD-YYYY
recurring <- FALSE              # Specify True for a recurring date range
#yearRange <- [2000,2016]       # If recurring = True, set yearRange, change start/end date to MM-DD

lat <- c(32.59069, 37.00583)        # Latitude of the point sites 
lon <- c(-106.84254, -119.00602)    # Longitude of the point sites
# id <- c("0","1")                      # ID for the point sites
id = "0"
category <- c("JORN", "TEAK") # Category for point sites

taskName <- 'NEON JORN TEAK NDVI'           # Enter name of the task here
taskType <- 'point'                    # Specify the task type, it can be either "area" or "point"
```

```{r}
# to successfully submit a task, the JSON object should be structured in a certain way. The code chunk below uses the information from the previous chunk to create a nested data frame. This nested data frame will be converted to JSON object that can be used to complete the request.

# Create a data frame including the date range for the request
date <- data.frame(startDate = startDate, endDate = endDate)
# Create a data frame including lat and long coordinates. ID and category name is optional.
coordinates <- data.frame(id = id, longitude = lon, latitude = lat, category = category)

task_info <- list(date, layers, coordinates)               # Create a list of data frames 
names(task_info) <- c("dates", "layers", "coordinates")   # Assign names

task <- list(task_info, taskName, taskType)               # Create a nested list 
names(task) <- c("params", "task_name", "task_type")      # Assign names 
remove(date, coordinates, task_info)              # Remove the variables that are not needed anymore
```


```{r}
# toJSON function from jsonlite package converts the type of data frame to a string that can be recognized as a JSON object to be submitted as a point request.

task_json <- toJSON(task,auto_unbox = TRUE)   # Convert to JSON object
```


```{r}
# Submit a Task Request
# Token information is needed to submit a request. Below the login token is assigned to a variable.

token <- paste("Bearer", fromJSON(token_response)$token)     # Save login token to a variable

# Below, post a call to the API task service, using the task_json created above

# Post the point request to the API task service
response <- POST(paste0(API_URL, "task"), 
                 body = task_json , 
                 encode = "json", 
                 add_headers(Authorization = token, "Content-Type" = "application/json"))

task_content <- content(response)                                 # Retrieve content of the request 
task_response <- prettify(toJSON(task_content, auto_unbox = TRUE))# Convert the content to JSON object
remove(response, task_content)                                    # Remove the variables that are not needed anymore
task_response                                                     # Print the prettified task response
```

```{r}
# Retrieve Task Status
# This API call will list all of the requests associated with your user account, automatically sorted by date descending with the most recent requests listed first. The AppEEARS API contains some helpful formatting resources. Below, limit the API response to 2 entries for the last 2 requests and set pretty to True to format the response as an organized JSON object to make it easier to read. Additional information on AppEEARS API retrieve task, pagination, and formatting can be found in the API documentation.

params <- list(limit = 2, pretty = TRUE)                            # Set up query parameters
# Request the task status of last 2 requests from task URL
response_req <- GET(paste0(API_URL,"task"), query = params, add_headers(Authorization = token))
response_content <- content(response_req)                           # Retrieve content of the request
status_response <- toJSON(response_content, auto_unbox = TRUE)      # Convert the content to JSON object
remove(response_req, response_content)                              # Remove the variables that are not needed anymore                         
prettify(status_response)         
```

```{r}
# task_id that was generated when submitting your request can also be used to retrieve a task status.

task_id <- fromJSON(task_response)$task_id                 # Extract the task_id of submitted point request
# Request the task status of a task with the provided task_id from task URL
status_req <- GET(paste0(API_URL,"task/", task_id), add_headers(Authorization = token)) 
status_content <- content(status_req)                       # Retrieve content of the request       
statusResponse <-toJSON(status_content, auto_unbox = TRUE)  # Convert the content to JSON object
stat <- fromJSON(statusResponse)$status                     # Assign the task status to a variable  
remove(status_req, status_content)                          # Remove the variables that are not needed anymore
prettify(statusResponse)                                    # Print the prettified response
```

```{r}
# Retrieve the task status every 5 seconds. The task status should be done to be able to download the output.

while (stat != 'done') {
  Sys.sleep(5)
  # Request the task status and retrieve content of request from task URL
  stat_content <- content(GET(paste0(API_URL,"task/", task_id), add_headers(Authorization = token)))
  stat <-fromJSON(toJSON(stat_content, auto_unbox = TRUE))$status    # Get the status
  remove(stat_content) 
  print(stat)
}
```

```{r}
# Download a Request
# Explore Files in Request Output
# Before downloading the request output, examine the files contained in the request output.

# Request the task bundle info from API bundle URL
response <- GET(paste0(API_URL, "bundle/", task_id), add_headers(Authorization = token))
response_content <- content(response)                          # Retrieve content of the request
bundle_response <- toJSON(response_content, auto_unbox = TRUE)  # Convert the content to JSON object
prettify(bundle_response)  
```

```{r}
# Download Files in a Request (Automation)
# The bundle API provides information about completed tasks. For any completed task, a bundle can be queried to return the files contained as a part of the task request. Below, call the bundle API and return all of the output files. Next, read the contents of the bundle in JSON format and loop through file_id to automate downloading all of the output files into the output directory. For more information, please see AppEEARS API Documentation.

bundle <- fromJSON(bundle_response)$files
for (id in bundle$file_id){
  # retrieve the filename from the file_id
  filename <- bundle[bundle$file_id == id,]$file_name     
  # create a destination directory to store the file in
  filepath <- paste(outDir,filename, sep = "/")
  suppressWarnings(dir.create(dirname(filepath)))
  # write the file to disk using the destination directory and file name 
  response <- GET(paste0(API_URL, "bundle/", task_id, "/", id),
                  write_disk(filepath, overwrite = TRUE),
                  progress(),
                  add_headers(Authorization = token))
}
```

## Question 3
**Use QA/QC values to filter out ‘poor quality’.**

```{r}
# Explore AppEEARS Quality Service
# The quality API provides quality details about all of the data products available in AppEEARS. Below are examples of how to query the quality API for listing quality products, layers, and values. The final example (Section 5c.) demonstrates how AppEEARS quality services can be leveraged to decode pertinent quality values for your data. For more information visit AppEEARS API documentation.
# 
# First, reset pagination to include offset which allows you to set the number of results to skip before starting to return entries. Next, make a call to list all of the data product layers and the associated quality product and layer information.

params <- list(limit = 6, offset = 20, pretty = TRUE)     # Set up the query parameters
q_req <- GET(paste0(API_URL, "quality"), query = params)  # Request the quality info from quality API_URL
q_content <- content(q_req)                               # Retrieve the content of request
q_response <- toJSON(q_content, auto_unbox = TRUE)        # Convert the info to JSON object
remove(params, q_req, q_content)                          # Remove the variables that are not needed 
prettify(q_response)                                      # Print the prettified quality information
```


```{r}
# List Quality Layers
# This API call will list all of the quality layer information for a product. For more information visit AppEEARS API documentation

productAndVersion <- 'MOD13Q1.006'                            # Assign ProductAndVersion to a variable 
# Request the quality info from quality API for a specific product
MOD13Q1_req <- GET(paste0(API_URL, "quality/", productAndVersion))
MOD13Q1_content <- content(MOD13Q1_req)                      # Retrieve the content of request
MOD13Q1_quality <- toJSON(MOD13Q1_content, auto_unbox = TRUE)# Convert the info to JSON object
remove(MOD13Q1_req, MOD13Q1_content)                         # Remove the variables that are not needed anymore
prettify(MOD13Q1_quality)                                     # Print the prettified quality information
```


```{r}
# Inspect Quality Values
# This API call will list all of the values for a given quality layer.

quality_layer <- '_250m_16_days_VI_Quality'                                 # assign a quality layer to a variable
# Request the specified quality layer info from quality API
quality_req <- GET(paste0(API_URL, "quality/",  productAndVersion, "/", quality_layer, sep = ""))
quality_content <- content(quality_req)                        # Retrieve the content of request
quality_response <- toJSON(quality_content, auto_unbox = TRUE) # Convert the info to JSON object
remove(quality_req, quality_content)                           # Remove the variables that are not needed 
prettify(quality_response)                                     # Print the quality response as a data frame
```


```{r}
# Decode Quality Values
# This API call will decode the bits for a given quality value.

quality_value <- 0                        # Assign a quality value to a variable 
# Request and retrieve information for provided quality value from quality API URL 
response <- content(GET(paste0(API_URL, "quality/", productAndVersion, "/", quality_layer, "/", quality_value)))
q_response <- toJSON(response, auto_unbox = TRUE)     # Convert the info to JSON object
remove(response)                                      # Remove the variables that are not needed anymore
prettify(q_response)                                  # Print the prettified response
```




```{r}
# Load Request Output and Visualize
# Here, load the CSV file containing the results from your request using readr package, and create some basic visualizations using the ggplot2 package.
# 
# Load a CSV
# Use the readr package to load the CSV file containing the results from the AppEEARS request.

# Make a list of csv files in the output directory
files <- list.files(outDir, pattern = "\\NEON-JORN-TEAK-NDVI-MOD13Q1-006-results.csv$") 
# Read the results
dfMOD <- read_csv(paste0(outDir,"/", files))
# filter for bad data 
dfMOD = dfMOD[dfMOD$MOD13Q1_006__250m_16_days_VI_Quality_MODLAND_Description == "VI produced with good quality",]

# Make a list of csv files in the output directory
files <- list.files(outDir, pattern = "\\NEON-JORN-TEAK-NDVI-MYD13Q1-006-results.csv$") 
# Read the results
dfMYD <- read_csv(paste0(outDir,"/", files))
# filter for bad data 
dfMYD = dfMYD[dfMYD$MYD13Q1_006__250m_16_days_VI_Quality_MODLAND_Description == "VI produced with good quality",]
```

## Question 4
**Plot 3 years of NDVI from MODIS AQUA and TERA as a timeseries.**

```{r}
# split df's by site
dfmod_JORN <- dfMOD %>% filter( Category =='JORN')
dfmod_TEAK <- dfMOD %>% filter( Category =='TEAK')
dfmyd_JORN <- dfMYD %>% filter( Category =='JORN')
dfmyd_TEAK <- dfMYD %>% filter( Category =='TEAK')

```


```{r}
# JORN
ggplot()+
  geom_line(data = dfmod_JORN,
            aes(x= Date, 
                y = MOD13Q1_006__250m_16_days_NDVI, 
                color = "TERA"))+
  geom_point(data = dfmod_JORN,aes(x= Date, y = MOD13Q1_006__250m_16_days_NDVI, color = "TERA")) +
  geom_line(data = dfmyd_JORN,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA")) +
  geom_point(data = dfmyd_JORN,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA"))+
  scale_color_manual(name = NULL, values=c("blue", "goldenrod")) +
  labs(title = "JORN Time Series", x = "Date", y = "NDVI")

```

```{r}
# TEAK
ggplot()+
  geom_line(data = dfmod_TEAK,
            aes(x= Date, 
                y = MOD13Q1_006__250m_16_days_NDVI, 
                color = "TERA"))+
  geom_point(data = dfmod_TEAK,aes(x= Date, y = MOD13Q1_006__250m_16_days_NDVI, color = "TERA")) +
  geom_line(data = dfmyd_TEAK,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA")) +
  geom_point(data = dfmyd_TEAK,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA"))+
  scale_color_manual(name = NULL, values=c("blue", "goldenrod")) +
  labs(title = "TEAK Time Series", x = "Date", y = "NDVI")
```

## Question 5
**Constrain a 3-week window for ‘peak greeness’ from MODIS and highlight it on your timeseries plot.**

```{r}
# what is the date with the highest greenness
which.max(dfmod_JORN$MOD13Q1_006__250m_16_days_NDVI) # 17

# make new object that is ~3 weeks JORN's peak greenness
rect = rect <- data.frame(xmin=dfmod_JORN$Date[15], xmax=dfmod_JORN$Date[18], ymin=-Inf, ymax=Inf)

# add this^ to timeseries plot
ggplot()+
  geom_line(data = dfmod_JORN,
            aes(x= Date, 
                y = MOD13Q1_006__250m_16_days_NDVI, 
                color = "TERA"))+
  geom_point(data = dfmod_JORN,aes(x= Date, y = MOD13Q1_006__250m_16_days_NDVI, color = "TERA")) +
  geom_line(data = dfmyd_JORN,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA")) +
  geom_point(data = dfmyd_JORN,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA"))+
  scale_color_manual(name = NULL, values=c("blue", "goldenrod")) +
  labs(title = "JORN Time Series", x = "Date", y = "NDVI") +
  geom_rect(data=rect, aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax),
            color="grey20", alpha=0.5,
            inherit.aes = FALSE)

```

```{r}
# im only going to consider TERA greennes for simplicity since aqua & tera are giving me different greenness peaks at TEAK

# what is the date with the highest greenness
which.max(dfmod_TEAK$MOD13Q1_006__250m_16_days_NDVI) # 14

# make new object that is ~3 weeks TEAK's peak greenness
rect = rect <- data.frame(xmin=dfmod_TEAK$Date[12], xmax=dfmod_TEAK$Date[15], ymin=-Inf, ymax=Inf)

# add this^ to timeseries plot
ggplot()+
  geom_line(data = dfmod_TEAK,
            aes(x= Date, 
                y = MOD13Q1_006__250m_16_days_NDVI, 
                color = "TERA"))+
  geom_point(data = dfmod_TEAK,aes(x= Date, y = MOD13Q1_006__250m_16_days_NDVI, color = "TERA")) +
  geom_line(data = dfmyd_TEAK,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA")) +
  geom_point(data = dfmyd_TEAK,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA"))+
  scale_color_manual(name = NULL, values=c("blue", "goldenrod")) +
  labs(title = "TEAK Time Series", x = "Date", y = "NDVI") +
  geom_rect(data=rect, aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax),
            color="grey20", alpha=0.5,
            inherit.aes = FALSE)
```

## Question 6
**Pull the canopy-level gcc90 from PhenoCam for the same site and the same time period as above.**

```{r, warning=F, message=F}
library(phenocamapi, quietly = T)
library(xROI, quietly = T)

# download phenocam data for JORN
JORN_1000 <- get_pheno_ts(site = 'NEON.D14.JORN.DP1.00033', vegType = 'GR', roiID = 1000, type = '3day')
# filter for the same date range
JORN_1000 = JORN_1000 %>%
  filter(date >= "2017-01-01",
         date <= "2019-12-31") 

# download phenocam data for TEAK
TEAK_1000 <- get_pheno_ts(site = 'NEON.D17.TEAK.DP1.00033', vegType = 'EN', roiID = 1000, type = '3day')
# filter for the same date range
# filter for the same date range
TEAK_1000 = TEAK_1000 %>%
  filter(date >= "2017-01-01",
         date <= "2019-12-31") 
```

## Question 7
**Plot the PhenoCam and MODIS timeseries on the same plot.**

```{r}
# JORN
ggplot()+
  geom_line(data = dfmod_JORN,aes(x= Date, 
                y = MOD13Q1_006__250m_16_days_NDVI, 
                color = "TERA"))+
  geom_point(data = dfmod_JORN,aes(x= Date, y = MOD13Q1_006__250m_16_days_NDVI, color = "TERA")) +
  geom_line(data = dfmyd_JORN,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA")) +
  geom_point(data = dfmyd_JORN,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA"))+
  geom_line(data = JORN_1000, aes(x = as.Date(date), y = JORN_1000$gcc_90, color = "Gcc"))+
  scale_color_manual(name = NULL, values=c("blue", "darkgreen","goldenrod" )) +
  labs(title = "JORN Time Series", x = "Date", y = "NDVI")

# TEAK
ggplot()+
  geom_line(data = dfmod_TEAK,
            aes(x= Date, 
                y = MOD13Q1_006__250m_16_days_NDVI, 
                color = "TERA"))+
  geom_point(data = dfmod_TEAK,aes(x= Date, y = MOD13Q1_006__250m_16_days_NDVI, color = "TERA")) +
  geom_line(data = dfmyd_TEAK,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA")) +
  geom_point(data = dfmyd_TEAK,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA"))+
  geom_line(data = TEAK_1000, aes(x = as.Date(date), y = gcc_90, color = "Gcc"))+
  scale_color_manual(name = NULL, values=c("blue", "darkgreen", "goldenrod")) +
  labs(title = "TEAK Time Series", x = "Date", y = "NDVI") 
```

## Question 8
**Constrain a 3-week window for ‘peak greeness’ from PhenoCam and highlight it on your timeseries.**

```{r}
# which date/row is the highest greenness at JORN?
which.max(JORN_1000$gcc_90) ## 55
# define a rectanlge around peak greenness
rectGccJORN = data.frame(xmin= as.Date(JORN_1000$date[52]), xmax=as.Date(JORN_1000$date[59]), ymin=-Inf, ymax=Inf)
# add the plot
ggplot()+
  geom_line(data = dfmod_JORN,aes(x= Date, 
                y = MOD13Q1_006__250m_16_days_NDVI, 
                color = "TERA"))+
  geom_point(data = dfmod_JORN,aes(x= Date, y = MOD13Q1_006__250m_16_days_NDVI, color = "TERA")) +
  geom_line(data = dfmyd_JORN,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA")) +
  geom_point(data = dfmyd_JORN,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA"))+
  geom_line(data = JORN_1000, aes(x = as.Date(date), y = JORN_1000$gcc_90, color = "Gcc"))+
  scale_color_manual(name = NULL, values=c("blue", "darkgreen","goldenrod" )) +
  labs(title = "JORN Time Series", x = "Date", y = "NDVI") +
  geom_rect(data=rectGccJORN, aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax),
            color="grey20", alpha=0.5,
            inherit.aes = FALSE)

# which date/row is the highest greenness at TEAK?
which.max(TEAK_1000$gcc_90) ## 32
# define a rectanlge around peak greenness
rectGccTEAK = data.frame(xmin= as.Date(TEAK_1000$date[29]), xmax=as.Date(TEAK_1000$date[34]), ymin=-Inf, ymax=Inf)
# add the plot
ggplot()+
  geom_line(data = dfmod_TEAK,aes(x= Date, 
                y = MOD13Q1_006__250m_16_days_NDVI, 
                color = "TERA"))+
  geom_point(data = dfmod_TEAK,aes(x= Date, y = MOD13Q1_006__250m_16_days_NDVI, color = "TERA")) +
  geom_line(data = dfmyd_TEAK,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA")) +
  geom_point(data = dfmyd_TEAK,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA"))+
  geom_line(data = TEAK_1000, aes(x = as.Date(date), y = TEAK_1000$gcc_90, color = "Gcc"))+
  scale_color_manual(name = NULL, values=c("blue", "darkgreen","goldenrod" )) +
  labs(title = "TEAK Time Series", x = "Date", y = "NDVI") +
  geom_rect(data=rectGccTEAK, aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax),
            color="grey20", alpha=0.5,
            inherit.aes = FALSE)
```

## Question 9
**Find the timing of the AOP flights that have occured at your sites over the same time period. Add those dates as a vertical line.**

JORN flight dates (b/w 2017 & 2019):

- 2017083115
- 2017082315
- 2017083015
- 2018083115
- 2019082615
- 2019082514
- 2019082715

TEAK flight dates:

- 2017062815
- 2017063016
- 2017062915
- 2017062715
- 2018061416
- 2018061515
- 2018061615
- 2019061715
- 2019061615
- 2019061515
- 2019061415

```{r}
JORNflights = lubridate::ymd_h(c(2017083115,
2017082315,
2017083015,
2018083115,
2019082615,
2019082514,
2019082715))

ggplot()+
  geom_line(data = dfmod_JORN,aes(x= Date, 
                y = MOD13Q1_006__250m_16_days_NDVI, 
                color = "TERA"))+
  geom_point(data = dfmod_JORN,aes(x= Date, y = MOD13Q1_006__250m_16_days_NDVI, color = "TERA")) +
  geom_line(data = dfmyd_JORN,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA")) +
  geom_point(data = dfmyd_JORN,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA"))+
  geom_line(data = JORN_1000, aes(x = as.Date(date), y = JORN_1000$gcc_90, color = "Gcc"))+
  scale_color_manual(name = NULL, values=c("blue", "darkgreen","goldenrod" )) +
  labs(title = "JORN Time Series", x = "Date", y = "NDVI") +
  geom_rect(data=rectGccJORN, aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax),
            color="grey20", alpha=0.5,
            inherit.aes = FALSE) +
  geom_vline(aes(xintercept = as.Date(JORNflights)), color = "red")



TEAKflights = lubridate::ymd_h(c(2017062815,
2017063016,
2017062915,
2017062715,
2018061416,
2018061515,
2018061615,
2019061715,
2019061615,
2019061515,
2019061415))

ggplot()+
  geom_line(data = dfmod_TEAK,aes(x= Date, 
                y = MOD13Q1_006__250m_16_days_NDVI, 
                color = "TERA"))+
  geom_point(data = dfmod_TEAK,aes(x= Date, y = MOD13Q1_006__250m_16_days_NDVI, color = "TERA")) +
  geom_line(data = dfmyd_TEAK,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA")) +
  geom_point(data = dfmyd_TEAK,aes(x= Date, y = MYD13Q1_006__250m_16_days_NDVI, color = "AQUA"))+
  geom_line(data = TEAK_1000, aes(x = as.Date(date), y = TEAK_1000$gcc_90, color = "Gcc"))+
  scale_color_manual(name = NULL, values=c("blue", "darkgreen","goldenrod" )) +
  labs(title = "TEAK Time Series", x = "Date", y = "NDVI") +
  geom_rect(data=rectGccTEAK, aes(xmin=xmin, xmax=xmax, ymin=ymin, ymax=ymax),
            color="grey20", alpha=0.5,
            inherit.aes = FALSE) +
  geom_vline(aes(xintercept = as.Date(TEAKflights)), color = "red")

```













```{r}
# Select the MOD11A2.006 LST Day column for the data from SOAP using the dplyr package.

lst_SOAP <- df %>%
  # Filter df
  filter(Category == "SOAP") %>%  
  # Select desired columns
  select(Latitude, Longitude, Date ,MOD11A2_006_LST_Day_1km, MOD11A2_006_LST_Night_1km)

# extract information for LST_DAY_1KM from MOD11_response of product service call from earlier in the tutorial.

#fromJSON(MOD11_response)$LST_Day_1km                        # Extract all the info for LST_Day_1km layer

fillValue <- fromJSON(MOD11_response)$LST_Day_1km$FillValue  # Assign fill value to a variable
unit <- fromJSON(MOD11_response)$LST_Day_1km$Units           # Assign unit to a variable
sprintf("Fill value for LST_DAY_1KM is: %i" ,fillValue)      # Print LST_DAY_1KM fill value
sprintf("Unit for LST_DAY_1KM is: %s" ,unit)                 # Print LST_DAY_1KM unit 
```


```{r}
# Plot Results (Line/Scatter Plots)
# Next, plot a time series of daytime LST for the selected point. Below, filter the LST data to exclude fill values.

lst_SOAP <- lst_SOAP %>%
  # exclude NoData
  filter(MOD11A2_006_LST_Day_1km != fillValue)%>%
  filter(MOD11A2_006_LST_Night_1km != fillValue)
```


```{r}
# plot LST Day as a time series with some additional formatting using ggplot2.

ggplot(lst_SOAP)+
  geom_line(aes(x= Date, y = MOD11A2_006_LST_Day_1km), size=1, color="blue")+
  geom_point(aes(x= Date, y = MOD11A2_006_LST_Day_1km), shape=18 , size = 3, color="blue")+
  labs(title = "Time Series",
       x = "Date",
       y = sprintf( "LST_Day_1km (%s)", unit))+
  scale_x_date(date_breaks = "16 day")+ 
  scale_y_continuous(limits = c(250, 325), breaks = seq(250, 325, 10))+
  theme(plot.title = element_text(face = "bold",size = rel(2.5),hjust = 0.5),
        axis.title = element_text(face = "bold",size = rel(1)),
        panel.background = element_rect(fill = "lightgray", colour = "black"),
        axis.text.x = element_text(face ="bold",color="black", angle= 315 , size = 10),
        axis.text.y = element_text(face ="bold",color="black", angle= 0, size = 10)
  )
```


```{r}
# using the tidyr package, the LST Day and Night values for Grand Canyon NP are being gathered in a single column to be used to make a plot including both LST_Day_1km and LST_Night_1km.

lst_SOAP_DN <- tidyr::gather(lst_SOAP, key = Tstat , value = LST, MOD11A2_006_LST_Day_1km, MOD11A2_006_LST_Night_1km)
lst_SOAP_DN[1:5,]                     # print the five first observations
```


```{r}
# plot LST Day and Night as a time series with some additional formatting.

ggplot(lst_SOAP_DN)+
  geom_line(aes(x= Date, y = LST, color = Tstat), size=1)+
  geom_point(aes(x= Date, y = LST, color = Tstat), shape=18 , size = 3)+
  scale_fill_manual(values=c("red", "blue"))+
  scale_color_manual(values=c('red','blue'))+
  labs(title = "Time Series",
       x = "Date",
       y = sprintf( "LST_Day_1km (%s)",unit))+
  scale_x_date(date_breaks = "16 day")+  
  scale_y_continuous(limits = c(250, 325), breaks = seq(250, 325, 10))+
  theme(plot.title = element_text(face = "bold",size = rel(2.5), hjust = 0.5),
        axis.title = element_text(face = "bold",size = rel(1)),
        panel.background = element_rect(fill = "lightgray", colour = "black"),
        axis.text.x = element_text(face ="bold",color="black", angle= 315 , size = 10),
        axis.text.y = element_text(face ="bold",color="black", angle= 0, size = 10),
        legend.position = "bottom",
        legend.title = element_blank()
  )
```


```{r}
# bring in the daytime LST data from SJER , and compare with daytime LST at SOAP , shown below in a scatterplot using ggplot2 package. Here, the dplyr is used to extract the LST_DAY_1km for SJER.

lst_SJER <- df %>%
  filter(MOD11A2_006_LST_Day_1km != fillValue) %>%        # Filter fill value 
  filter(Category == "SJER")%>%                           # Filter SJER national park
  select(Date, MOD11A2_006_LST_Day_1km)                   # Select desired columns
```


```{r}
# make a scatterplot.


ggplot()+
  geom_point(aes(x=lst_SOAP$MOD11A2_006_LST_Day_1km, y=lst_SJER$MOD11A2_006_LST_Day_1km[-11]), shape=18 , size = 3, color="blue")+
  labs(title = "MODIS LST: SOAP vs. SJER, 2020",
       x = sprintf("SOAP: LST_Day_1km (%s)",unit),
       y = sprintf( "SJER: LST_Day_1km (%s)",unit))+
  theme(plot.title = element_text(face = "bold",size = rel(1.5), hjust = 0.5),
        axis.title = element_text(face = "bold",size = rel(1)),
        panel.background = element_rect(fill = "lightgray", colour = "black"),
        axis.text.x = element_text(face ="bold",color="black", size = 10),
        axis.text.y = element_text(face ="bold",color="black", size = 10)
  )

# this example can provide a template to use for your own research workflows. Leveraging the AppEEARS API for searching, extracting, and formatting analysis ready data, and loading it directly into R means that you can keep your entire research workflow in a single software program, from start to finish.

```


# NASA EOS Coding Lab #2
## Question 1
**Choose two NEON sites in different ecoregions. Then complete the following for each of your two NEON sites:**

```{r}
sites = c("JORN","BART")
```


## Question 2
**Using your Earth Data account submit a point-based request to AppEEARS to pull 250m NDVI from AQUA and TERA for 2017, 2018, & 2019**

```{r}

```



